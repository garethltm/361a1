{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task1 (Coding)\n",
    "\n",
    "In this task, we will implement a full ML classifier based on decision trees (in python using Jupyter notebook). We will use the Mushroom Data Set to train and evaluate your classifier. This dataset comes from the UCI ML repository. (Hint: There are missing values in this dataset. At this particular time, you may ignore instances that have missing values and just remove them, or replace missing values with the mean value of the column. Please note that there are other ways of pre-processing data which we have not seen yet.)\n",
    "\n",
    "You can use libraries e.g., Pandas, NumPy but you may NOT use any prebuilt decision tree packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'uci_id': 73, 'name': 'Mushroom', 'repository_url': 'https://archive.ics.uci.edu/dataset/73/mushroom', 'data_url': 'https://archive.ics.uci.edu/static/public/73/data.csv', 'abstract': 'From Audobon Society Field Guide; mushrooms described in terms of physical characteristics; classification: poisonous or edible', 'area': 'Biology', 'tasks': ['Classification'], 'characteristics': ['Multivariate'], 'num_instances': 8124, 'num_features': 22, 'feature_types': ['Categorical'], 'demographics': [], 'target_col': ['poisonous'], 'index_col': None, 'has_missing_values': 'yes', 'missing_values_symbol': 'NaN', 'year_of_dataset_creation': 1981, 'last_updated': 'Thu Aug 10 2023', 'dataset_doi': '10.24432/C5959T', 'creators': [], 'intro_paper': None, 'additional_info': {'summary': \"This data set includes descriptions of hypothetical samples corresponding to 23 species of gilled mushrooms in the Agaricus and Lepiota Family (pp. 500-525).  Each species is identified as definitely edible, definitely poisonous, or of unknown edibility and not recommended.  This latter class was combined with the poisonous one.  The Guide clearly states that there is no simple rule for determining the edibility of a mushroom; no rule like ``leaflets three, let it be'' for Poisonous Oak and Ivy.\", 'purpose': None, 'funded_by': None, 'instances_represent': None, 'recommended_data_splits': None, 'sensitive_data': None, 'preprocessing_description': None, 'variable_info': '     1. cap-shape:                bell=b,conical=c,convex=x,flat=f, knobbed=k,sunken=s\\r\\n     2. cap-surface:              fibrous=f,grooves=g,scaly=y,smooth=s\\r\\n     3. cap-color:                brown=n,buff=b,cinnamon=c,gray=g,green=r, pink=p,purple=u,red=e,white=w,yellow=y\\r\\n     4. bruises?:                 bruises=t,no=f\\r\\n     5. odor:                     almond=a,anise=l,creosote=c,fishy=y,foul=f, musty=m,none=n,pungent=p,spicy=s\\r\\n     6. gill-attachment:          attached=a,descending=d,free=f,notched=n\\r\\n     7. gill-spacing:             close=c,crowded=w,distant=d\\r\\n     8. gill-size:                broad=b,narrow=n\\r\\n     9. gill-color:               black=k,brown=n,buff=b,chocolate=h,gray=g, green=r,orange=o,pink=p,purple=u,red=e, white=w,yellow=y\\r\\n    10. stalk-shape:              enlarging=e,tapering=t\\r\\n    11. stalk-root:               bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,rooted=r,missing=?\\r\\n    12. stalk-surface-above-ring: fibrous=f,scaly=y,silky=k,smooth=s\\r\\n    13. stalk-surface-below-ring: fibrous=f,scaly=y,silky=k,smooth=s\\r\\n    14. stalk-color-above-ring:   brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\\r\\n    15. stalk-color-below-ring:   brown=n,buff=b,cinnamon=c,gray=g,orange=o, pink=p,red=e,white=w,yellow=y\\r\\n    16. veil-type:                partial=p,universal=u\\r\\n    17. veil-color:               brown=n,orange=o,white=w,yellow=y\\r\\n    18. ring-number:              none=n,one=o,two=t\\r\\n    19. ring-type:                cobwebby=c,evanescent=e,flaring=f,large=l, none=n,pendant=p,sheathing=s,zone=z\\r\\n    20. spore-print-color:        black=k,brown=n,buff=b,chocolate=h,green=r, orange=o,purple=u,white=w,yellow=y\\r\\n    21. population:               abundant=a,clustered=c,numerous=n, scattered=s,several=v,solitary=y\\r\\n    22. habitat:                  grasses=g,leaves=l,meadows=m,paths=p, urban=u,waste=w,woods=d', 'citation': None}}\n",
      "                        name     role         type demographic  \\\n",
      "0                  poisonous   Target  Categorical        None   \n",
      "1                  cap-shape  Feature  Categorical        None   \n",
      "2                cap-surface  Feature  Categorical        None   \n",
      "3                  cap-color  Feature       Binary        None   \n",
      "4                    bruises  Feature  Categorical        None   \n",
      "5                       odor  Feature  Categorical        None   \n",
      "6            gill-attachment  Feature  Categorical        None   \n",
      "7               gill-spacing  Feature  Categorical        None   \n",
      "8                  gill-size  Feature  Categorical        None   \n",
      "9                 gill-color  Feature  Categorical        None   \n",
      "10               stalk-shape  Feature  Categorical        None   \n",
      "11                stalk-root  Feature  Categorical        None   \n",
      "12  stalk-surface-above-ring  Feature  Categorical        None   \n",
      "13  stalk-surface-below-ring  Feature  Categorical        None   \n",
      "14    stalk-color-above-ring  Feature  Categorical        None   \n",
      "15    stalk-color-below-ring  Feature  Categorical        None   \n",
      "16                 veil-type  Feature       Binary        None   \n",
      "17                veil-color  Feature  Categorical        None   \n",
      "18               ring-number  Feature  Categorical        None   \n",
      "19                 ring-type  Feature  Categorical        None   \n",
      "20         spore-print-color  Feature  Categorical        None   \n",
      "21                population  Feature  Categorical        None   \n",
      "22                   habitat  Feature  Categorical        None   \n",
      "\n",
      "                                          description units missing_values  \n",
      "0                                                None  None             no  \n",
      "1   bell=b,conical=c,convex=x,flat=f, knobbed=k,su...  None             no  \n",
      "2                fibrous=f,grooves=g,scaly=y,smooth=s  None             no  \n",
      "3   brown=n,buff=b,cinnamon=c,gray=g,green=r, pink...  None             no  \n",
      "4                                      bruises=t,no=f  None             no  \n",
      "5   almond=a,anise=l,creosote=c,fishy=y,foul=f, mu...  None             no  \n",
      "6            attached=a,descending=d,free=f,notched=n  None             no  \n",
      "7                         close=c,crowded=w,distant=d  None             no  \n",
      "8                                    broad=b,narrow=n  None             no  \n",
      "9   black=k,brown=n,buff=b,chocolate=h,gray=g, gre...  None             no  \n",
      "10                             enlarging=e,tapering=t  None             no  \n",
      "11  bulbous=b,club=c,cup=u,equal=e, rhizomorphs=z,...  None            yes  \n",
      "12                 fibrous=f,scaly=y,silky=k,smooth=s  None             no  \n",
      "13                 fibrous=f,scaly=y,silky=k,smooth=s  None             no  \n",
      "14  brown=n,buff=b,cinnamon=c,gray=g,orange=o, pin...  None             no  \n",
      "15  brown=n,buff=b,cinnamon=c,gray=g,orange=o, pin...  None             no  \n",
      "16                              partial=p,universal=u  None             no  \n",
      "17                  brown=n,orange=o,white=w,yellow=y  None             no  \n",
      "18                                 none=n,one=o,two=t  None             no  \n",
      "19  cobwebby=c,evanescent=e,flaring=f,large=l, non...  None             no  \n",
      "20  black=k,brown=n,buff=b,chocolate=h,green=r, or...  None             no  \n",
      "21  abundant=a,clustered=c,numerous=n, scattered=s...  None             no  \n",
      "22  grasses=g,leaves=l,meadows=m,paths=p, urban=u,...  None             no  \n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "mushroom = fetch_ucirepo(id=73) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = mushroom.data.features \n",
    "y = mushroom.data.targets \n",
    "  \n",
    "# metadata \n",
    "print(mushroom.metadata) \n",
    "  \n",
    "# variable information \n",
    "print(mushroom.variables) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the basic decision tree procedure as discussed in the lectures. \n",
    "Implement 'DecisionTree' algorithm with a train procedure. \n",
    "Implement the information gain criterion as described in our lectures. \n",
    "\n",
    "In your report use one or two sentences to discuss the output (the output of the training procedure is the trained decision tree which is a representation of the if-then-else rules). \n",
    "\n",
    "You may print out your decision tree (you don't have to, however it might help you discuss the trained trees)  (This may be large - consider the best way to print it). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[0;32m     65\u001b[0m tree_classifier \u001b[38;5;241m=\u001b[39m DecisionTree()\n\u001b[1;32m---> 66\u001b[0m tree_classifier\u001b[38;5;241m.\u001b[39mfit(\u001b[43mX_train\u001b[49m, y_train)\n\u001b[0;32m     67\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m tree_classifier\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class DecisionTree:\n",
    "    def __init__(self):\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        def entropy(labels):\n",
    "            # Calculate entropy for a set of labels\n",
    "            total_samples = len(labels)\n",
    "            label_counts = np.array(list(Counter(labels).values()))\n",
    "            probabilities = label_counts / total_samples\n",
    "            return -np.sum(probabilities * np.log2(probabilities))\n",
    "\n",
    "        def information_gain(parent_entropy, left_labels, right_labels):\n",
    "            # Calculate Information Gain based on parent entropy and child entropies\n",
    "            total_samples = len(left_labels) + len(right_labels)\n",
    "            left_weight = len(left_labels) / total_samples\n",
    "            right_weight = len(right_labels) / total_samples\n",
    "            left_entropy = entropy(left_labels)\n",
    "            right_entropy = entropy(right_labels)\n",
    "            return parent_entropy - (left_weight * left_entropy) - (right_weight * right_entropy)\n",
    "\n",
    "        def find_best_split(X, y):\n",
    "            parent_entropy = entropy(y)\n",
    "            best_feature, best_threshold, best_gain = None, None, -float('inf')\n",
    "            for feature in X.columns:\n",
    "                unique_values = np.unique(X[feature])\n",
    "                for threshold in unique_values:\n",
    "                    left_mask = X[feature] <= threshold\n",
    "                    right_mask = ~left_mask\n",
    "                    left_labels, right_labels = y[left_mask], y[right_mask]\n",
    "                    gain = information_gain(parent_entropy, left_labels, right_labels)\n",
    "                    if gain > best_gain:\n",
    "                        best_gain, best_feature, best_threshold = gain, feature, threshold\n",
    "            return best_feature, best_threshold\n",
    "\n",
    "        def build_tree(X, y):\n",
    "            if len(set(y)) == 1:\n",
    "                return y[0]\n",
    "            best_feature, best_threshold = find_best_split(X, y)\n",
    "            left_mask = X[best_feature] <= best_threshold\n",
    "            right_mask = ~left_mask\n",
    "            left_tree = build_tree(X[left_mask], y[left_mask])\n",
    "            right_tree = build_tree(X[right_mask], y[right_mask])\n",
    "            return {'feature': best_feature, 'threshold': best_threshold,\n",
    "                    'left': left_tree, 'right': right_tree}\n",
    "\n",
    "        self.tree = build_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        def predict_tree(node, sample):\n",
    "            if isinstance(node, int):\n",
    "                return node\n",
    "            feature, threshold, left, right = node['feature'], node['threshold'], node['left'], node['right']\n",
    "            if sample[feature] <= threshold:\n",
    "                return predict_tree(left, sample)\n",
    "            else:\n",
    "                return predict_tree(right, sample)\n",
    "\n",
    "        return [predict_tree(self.tree, sample) for _, sample in X.iterrows()]\n",
    "    \n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "tree_classifier = DecisionTree()\n",
    "tree_classifier.fit(X_train, y_train)\n",
    "y_pred = tree_classifier.predict(X_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
